import logging
import re
from datetime import datetime
from typing import List, Optional

from fastapi.openapi import utils
from pydantic import DateTimeError, ValidationError
from pydantic.datetime_parse import parse_datetime
from shapely.geometry import shape
from stac_fastapi.api.app import StacApi
from stac_fastapi.types.links import CollectionLinks, ItemLinks
from stac_fastapi.types.stac import Collection, Item
from stac_pydantic import Collection as pydantic_collection
from stac_pydantic import Item as pydantic_item
from stac_pydantic.collection import SpatialExtent, TimeInterval
from stac_pydantic.item import ItemProperties

from mqs.config import settings

logger = logging.getLogger(__name__)
logger.setLevel(20)

# This is to include servers in the openapi.json
def custom_openapi(api: StacApi):
    app = api.app

    def wrapper():
        if app.openapi_schema:
            return app.openapi_schema
        openapi_schema = utils.get_openapi(
            title=api.title,
            description=api.description,
            version=api.api_version,
            routes=app.routes,
            tags=app.openapi_tags,
            servers=app.servers,
        )

        app.openapi_schema = openapi_schema
        return app.openapi_schema

    return wrapper


def is_valid_collection(collection: dict) -> bool:
    try:
        pydantic_collection(**collection)
        return True
    except ValidationError as ex:
        logger.warning("Could not validate STAC Collection: %.80s", collection)
        logger.warning(ex)
        return False


def make_valid_collection(collection: dict) -> Collection:
    if is_valid_collection(collection):
        if "summaries" in collection.keys():
            collection["summaries"] = _fix_summaries(collection["summaries"])
        else:
            collection["summaries"] = {}
        return collection
    # auto-fill required fields (assuming ID is present!)
    description = (
        "This STAC Collection is part of the data federation and its description was auto-generated by the EO-MQS."
        if "description" not in collection.keys() or collection["description"] is None
        else collection["description"]
    )
    collection_links = (
        CollectionLinks(
            collection_id=collection["id"],
            base_url=settings.app_host,
        ).create_links()
        if "links" not in collection.keys() or collection["links"] is None
        else collection["links"]
    )
    license = (
        "proprietary"
        if "license" not in collection.keys() or collection["license"] is None
        else collection["license"]
    )
    extent = get_extent(collection)
    #
    # modify
    collection["description"] = description
    collection["links"] = collection_links
    collection["license"] = license
    collection["extent"] = extent

    # try to fix summaries
    if "summaries" in collection.keys():
        collection["summaries"] = _fix_summaries(collection["summaries"])
    else:
        collection["summaries"] = {}

    return collection if is_valid_collection(collection) else None


def _fix_summaries(summaries: dict) -> dict:
    # try fix summaries (tmp fix)
    summary_fixed = {}
    if not summaries:
        return summary_fixed
    for k, v in summaries.items():
        if k == "constellation" and not isinstance(v, list):
            summary_fixed[k] = list(v)
        elif k == "datetime":
            minnull = "minimum" in v.keys() and v["minimum"] is None
            maxnull = "maximum" in v.keys() and v["maximum"] is None
            if minnull and maxnull:
                continue
        else:
            summary_fixed[k] = v
    return summary_fixed


def get_extent(stac: dict) -> list:
    extent = {}
    spatial_extent = [[-180.0, -90.0, 180.0, 90.0]]
    temporal_extent = [[None, None]]
    if "extent" in stac.keys():
        extent = stac["extent"]
    if "spatial" in extent.keys():
        try:
            _spatial_extent = extent["spatial"]["bbox"]
            SpatialExtent(bbox=_spatial_extent)
        except (ValidationError, KeyError, TypeError) as ex:
            logger.warning("Cannot validate spatial extent. Set to %s.", spatial_extent)
            logger.warning(ex)
        else:
            spatial_extent = _spatial_extent
    if "temporal" in extent.keys():
        try:
            _temporal_extent = extent["temporal"]["interval"]
            TimeInterval(interval=_temporal_extent)
        except (ValidationError, KeyError, TypeError) as ex:
            logger.warning(
                "Cannot validate temporal extent. Set to %s.", temporal_extent
            )
            logger.warning(ex)
        else:
            temporal_extent = _temporal_extent
    extent["spatial"] = {"bbox": spatial_extent}
    extent["temporal"] = {"interval": temporal_extent}
    return extent


def is_valid_item(item: dict) -> bool:
    try:
        pydantic_item(**item)
        return True
    except ValidationError as ex:
        logger.warning("Could not validate STAC Item: %.80s", item)
        logger.warning(ex)
        return False


def make_valid_item(item: dict) -> Item:
    if is_valid_item(item):
        return item
    # auto-fill required fields (assuming ID is present!)
    properties = get_properties(item)
    item_links = (
        ItemLinks(
            collection_id=item["collection"],
            item_id=item["id"],
            base_url=settings.app_host,
        ).create_links()
        if "links" not in item.keys() or item["links"] is None
        else item["links"]
    )
    assets = (
        {} if "assets" not in item.keys() or item["assets"] is None else item["assets"]
    )
    bbox = get_bbox_item(item)
    #
    # modify
    item["properties"] = properties
    item["links"] = item_links
    item["assets"] = assets
    if bbox:
        item["bbox"] = bbox
    return item if is_valid_item(item) else None


def get_properties(stac: dict) -> dict:
    properties = {}
    datetime = "1900-01-01T00:00:00Z"
    if "properties" in stac.keys():
        properties = stac["properties"]

    if not _has_date(properties):
        dates = _heuristic_date_search(properties)
        for k, v in dates.items():
            properties[k] = v

    for date_type in ("datetime", "start_datetime", "end_datetime"):
        if date_type in properties.keys():
            properties[date_type] = _fix_date_formats(properties[date_type])

    if _has_date(properties) and not _has_datetime(properties):
        _datetime = None
        try:
            t1 = parse_datetime(properties["start_datetime"])
            t2 = parse_datetime(properties["end_datetime"])
            _datetime = t1 + (t2 - t1) / 2.0
        except (ValidationError, KeyError, TypeError) as ex:
            logger.warning("Calculation of datetime failed.")
            logger.warning(ex)
        else:
            if _datetime:
                properties["datetime"] = _datetime

    if _has_date(properties):
        try:
            prop = ItemProperties(**properties)
            if not prop.datetime:
                properties["datetime"] = (
                    prop.start_datetime + (prop.end_datetime - prop.start_datetime) / 2
                )
        except (ValidationError, KeyError, TypeError) as ex:
            logger.warning("Cannot validate properties. Set datetime to %s.", datetime)
            logger.warning(ex)
            properties["datetime"] = datetime
    return properties


def _has_date(properties: dict) -> bool:
    return (
        "start_datetime" in properties.keys() and "end_datetime" in properties.keys()
    ) or ("datetime" in properties.keys())


def _has_datetime(properties: dict) -> bool:
    return "datetime" in properties.keys()


def _heuristic_date_search(properties: dict):
    dates_found = {}
    for k, v in properties.items():
        try:
            parse_datetime(v)
        except DateTimeError as ex:
            logger.warning("Heuristic datetime search: not a datetime: %s", k)
            logger.warning(ex)
        else:
            if isinstance(v, str):
                try:
                    int(v)
                except ValueError:
                    dates_found[k] = v
                    logger.warning("Possible candidate found: %s", v)
                else:
                    logger.warning("This does not look like a datetime object: %s", v)

    dates = {}
    for k, v in dates_found.items():
        kl = k.lower()
        if "start" in kl or "begin" in kl:
            dates["start_datetime"] = v
            logger.warning("Used %s to set start_datetime!", k)
        elif "stop" in kl or "end" in kl:
            dates["end_datetime"] = v
            logger.warning("Used %s to set end_datetime!", k)
        elif "create" in kl or "generat" in kl or "process" in kl or "product" in kl:
            dates["datetime"] = v
            logger.warning("Used %s to set datetime!", k)
        elif "datetime" not in dates.keys():
            dates["datetime"] = v
            logger.warning("Used %s to set datetime!", k)

    return dates


def _fix_date_formats(datetime_str: str = ""):
    # issue with stactools-sentinel2 (?) at the moment
    if isinstance(datetime_str, datetime):
        return datetime_str.strftime("%Y-%m-%dT%H:%M:%S.%fZ")
    datetime_str_fix = datetime_str
    try:
        _datetime_str_fix = datetime_str.replace("ZZ", "Z")
    except Exception as ex:
        logger.warning("Cannot fix datetime string.")
        logger.warning(ex)
    else:
        datetime_str_fix = _datetime_str_fix
    return datetime_str_fix


def get_bbox_item(stac: dict) -> list:
    bbox = None
    has_geom = "geometry" in stac.keys() and stac["geometry"] is not None
    needs_bbox = has_geom and (not "bbox" in stac.keys() or stac["bbox"] is None)
    if needs_bbox:
        geom_bounds = shape(stac["geometry"]).bounds
        bbox = list(geom_bounds)
    return bbox


def fix_duplicate_slashes(url: str) -> str:
    pattern = r"(?<!:)/+"
    return re.sub(pattern, "/", url)


def filter_spatially(item: dict, filter_geom: shape = None) -> bool:
    if not filter_geom:
        return True
    has_geom = "geometry" in item.keys() and item["geometry"] is not None
    has_bbox = "bbox" in item.keys() and item["bbox"] is not None
    geom = None
    if has_geom:
        geom = item["geometry"]
    elif has_bbox:
        geom = item["bbox"]
    else:
        return False
    intersects = False
    try:
        _intersects = shape(geom).intersects(shape(filter_geom))
    except Exception as ex:
        logger.warning("Cannot perform spatial filtering!")
        logger.warning(ex)
    else:
        intersects = _intersects
    return intersects


def filter_temporally(
    item: dict, start_date: datetime = None, end_date: datetime = None
) -> bool:
    properties = get_properties(item)
    # get item dates
    t1 = None
    t2 = None
    tc = None
    if "start_datetime" in properties.keys():
        try:
            _t1 = parse_datetime(properties["start_datetime"])
        except Exception as ex:
            logger.warning("Cannot parse start_date.")
            logger.warning(ex)
        else:
            t1 = _t1
    if "end_datetime" in properties.keys():
        try:
            _t2 = parse_datetime(properties["end_datetime"])
        except Exception as ex:
            logger.warning("Cannot parse end_datetime.")
            logger.warning(ex)
        else:
            t2 = _t2
    if "datetime" in properties.keys():
        try:
            _tc = parse_datetime(properties["datetime"])
        except Exception as ex:
            logger.warning("Cannot parse datetime.")
            logger.warning(ex)
        else:
            tc = _tc
    # carry out comparisons
    is_overlap = False
    if t1 or t2:
        is_overlap = _temporal_overlap(
            start_date_a=start_date, end_date_a=end_date, start_date_b=t1, end_date_b=t2
        )
    elif tc:
        is_overlap = _temporal_overlap(
            start_date_a=start_date, end_date_a=end_date, start_date_b=tc, end_date_b=tc
        )

    return is_overlap


def _temporal_overlap(
    start_date_a: datetime,
    end_date_a: datetime,
    start_date_b: datetime,
    end_date_b: datetime,
) -> bool:
    # determne max start date
    if start_date_a and start_date_b:
        start_date = max(start_date_a, start_date_a)
    elif not start_date_a and start_date_b:
        start_date = start_date_b
    elif start_date_a and not start_date_b:
        start_date = start_date_a
    else:
        logger.warning("Start dates cannot be mutually None.")
        return False
    # determne min end date
    if end_date_a and end_date_b:
        end_date = min(end_date_a, end_date_b)
    elif not end_date_a and end_date_b:
        end_date = end_date_b
    elif end_date_a and not end_date_b:
        end_date = end_date_a
    else:
        logger.warning("End dates cannot be mutually None.")
        return False
    # make comparison
    return start_date <= end_date


def filter_collections(item: dict, collections: Optional[List[str]] = None) -> bool:
    if not collections:
        return True
    is_collection = False
    if "collection" in item.keys():
        is_collection = item["collection"] in collections
    return is_collection


def filter_ids(item: dict, ids: Optional[List[str]] = None) -> bool:
    if not ids:
        return True
    is_id = False
    if "id" in item.keys():
        is_id = item["id"] in ids
    return is_id


def remove_provider_from_collection_ids(
    collections: Optional[List[str]] = None,
) -> Optional[List[str]]:
    # remove data provider from collection ids
    collections_stac = []
    if collections:
        collections_list = (
            collections.split(",")
            if not isinstance(collections, (list, List))
            else collections
        )
        for col in collections_list:
            if settings.collection_delimiter in col:
                collections_stac.append(col.split(settings.collection_delimiter)[1])
            else:
                collections_stac.append(col)
    return collections_stac


def skip_provider_if_all_specified(
    provider_id: str,
    collections: Optional[List[str]] = None,
) -> bool:
    # if all collections are specified including a provider id, check for a match and return bool
    provider_can_be_skipped = False
    if collections:
        collections_list = (
            collections.split(",")
            if not isinstance(collections, (list, List))
            else collections
        )
        n_collections = len(collections_list)
        providers = []
        for col in collections_list:
            if settings.collection_delimiter in col:
                provider = col.split(settings.collection_delimiter)[0]
                if provider:
                    providers.append(provider)
        n_providers = len(providers)
        n_equal = n_collections == n_providers
        provider_can_be_skipped = n_equal and (provider_id not in providers)
    return provider_can_be_skipped
